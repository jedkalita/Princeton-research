import math
import numpy as np
from scipy.stats import rv_discrete
import threading
import time
import logging
import random

logging.basicConfig(level=logging.DEBUG,
                    format='(%(threadName)-9s) %(message)s', )

class Environment: #the class that will be simulating the adversary in terms of generating rewards back and forth with
    #each player
    def __init__(self, numPlayers, N, cost_scenarios):
        self.numPlayers = numPlayers #no of players in the game
        self.N = N #no of strategies that each player has
        self.cost_scenarios = cost_scenarios #the cost scenarios list

    def generateRewards(self, t, strategiesPicked): #generate the cost vector for all players
    #now, we have to literally calculate all of the possible permutations between other players and their strategies
        logging.debug("About to generate rewards for time : %d" %t)
        for j in range(len(strategiesPicked)):
            logging.debug("Player %d executed strategy %d" % (j, strategiesPicked[j]))
        totalScenarios = (self.numPlayers - 1) * self.N #the different scenarios of strategies per remaining players that could
        #happen

        #now, decode from the strategies picked which index within the cost_scenarios to get the cost from
        sum = int(0)
        for i in range(self.numPlayers):
            sum = sum + (int(math.pow(self.N, i)) * strategiesPicked[i])
        print("sum is : %d" % (sum))

        costs_decided = []
        for i in range(self.numPlayers):
            costs_decided.append(self.cost_scenarios[sum][i])
        logging.debug("Finished generating rewards for time %d" %(t))
        return costs_decided #return the cost for all players

class Player:
    def __init__(self, T, N):
        self.T = T #to make the matrix
        self.N = N #the number of actions/strategies that the player has
        self.weight = np.ones((self.N), dtype=float) #each player will have their cost vector indexed acc to the time instance
        #this has been initialized to 1.0 for all, but we really only care about for t=1 for all actions acc to the
        #algorithm
        self.epsilon = math.sqrt(math.log(self.N) / self.T) #the value of learning parameter for the no regret case
        # under known T

    def pickStrategy(self): #this will be called for the t+1th time instance after the player has picked a strategy
        #acc to the weight matrix that existed at time t
        weighted_total = sum(self.weight[:]) #get the weighted sum of all strategies of the player at time t - 1
        #the above goes in the denominator
        probability = self.weight[:] / weighted_total #get the probabilities for the individual weights to
        #randomize over
        values_over = self.weight[:] #the values over which we will pick, essentially we only need the index
        #of the strategy, hence the range() function below
        distrib = rv_discrete(values = (range(len(values_over)), probability)) #generate the distribution
        return (distrib.rvs(size = 1)) #pick one randomized choice from the distribution created above and return, this
        #will be the strategy that the player picks, and this index will then be changed based on the cost vector fed
        #by the environment/adversary, who will keep track of the cost of each particular strategy

    def changeWeight(self, costs_decided, t, strategiesPicked, playerID): #given cost vector at time t generated by environment/adversary,
        #change the weight of the pickedStrategy at time t for time t+1
        if t == self.T - 1: #the last time step
            return #just return
        logging.debug("Played ID: %d, executed strategy: %d" % (playerID, strategiesPicked[playerID]))
        self.weight[strategiesPicked[playerID]] = self.weight[strategiesPicked[playerID]] * \
                                                  math.pow((1 - self.epsilon), costs_decided[playerID])
        #the multiplicative update formula
        print("Player ID: %d " % playerID)
        print(self.weight)

def play(players, playerID, strategiesPicked): #to play each game at each time step
    strategyPicked = players[playerID].pickStrategy() #pick the strategy
    strategiesPicked.append(strategyPicked) #for this iteration of time, per player strategy is put in a list
    #now, based upon the combination of picked strategies the same loss will be applied to each individual player

def changeWeights(players, playerID, strategiesPicked, costs_decided, t): #the function to change weights for each player
    players[playerID].changeWeight(costs_decided, t, strategiesPicked, playerID)


if __name__ == '__main__':
    Tstr = input("Enter a time horizon: ")
    T = int(Tstr) #the total number of time divisions, T
    nof = raw_input("Enter name of file (rps/ct(.txt)) : ") #get the file depending on the game to be played that will
    #store all of the number of players/no of strategies/cost per strategy under different scenario
    fh = open(nof, 'r') #the file handler

    N = int(fh.readline())  # total no. of actions
    NumPl = int(fh.readline())  # no. of players
    cost_scenarios = []  # cost config for each scenario
    num_costs = int(math.pow(N, NumPl))  # the total number of different cost configurations possible
    #now, read from the input file the associated costs
    for i in range(num_costs):  # a loop to fill up the cost per strategy per player acquired from the input file
        cost = []
        line = fh.readline().split(" ")
        for k in range(len(line)):
            if (line[k] != '\n'):
                cost.append(float(line[k]))
        cost_scenarios.append(cost)


    env = Environment(NumPl, N, cost_scenarios) #create the environment object
    #now, initialize the players in a loop
    players = [] #the list of players
    for i in range(NumPl): #for each player
        players.append(Player(T, N)) #each player has been initialized

    for i in range(T): #at each time step, for each player, select an action and based on the scenario provided,
        #decide on the next action
        strategiesPicked = []  # a list to hold the individual strategies picked by each player
        for j in range(NumPl):
            t = threading.Thread(target=play, args=(players, j, strategiesPicked)) #first, pick a strategy
            t.start()

        #now, close all the threads
        logging.debug("Waiting for all threads after picking strategies.")
        main_thread = threading.currentThread()
        for t in threading.enumerate():
            if t is not main_thread:
                t.join()

        #now, call the environment variable to calculate the cost based on the combination
        costs_decided = env.generateRewards(i, strategiesPicked)
        #now, after all the players have  picked an individual strategy, decide on a cost for all of them
        for j in range(NumPl):
            t = threading.Thread(target=changeWeights, args=(players, j, strategiesPicked, costs_decided, i))
            t.start()

        #now join all the threads before moving on to the next time step
        logging.debug("Waiting for all threads after finishing setting weights.")
        for t in threading.enumerate():
            if t is not main_thread:
                t.join()
        print("Moving on to time step %d" % (i + 1))

    print("Game over...")
